{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, make_scorer, precision_score, recall_score\n",
    "from sklearn.model_selection import KFold, RandomizedSearchCV, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import torch\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define functions to encode sentences & read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_sentences_sbert(df, column_name):\n",
    "    # Initialize SBERT model\n",
    "    model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "    # Initialize a column for document-level embeddings\n",
    "    df['embeddings'] = None\n",
    "\n",
    "    for index, row in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "        # Ensure the row value is a string before splitting\n",
    "        text = str(row[column_name])\n",
    "        \n",
    "        # Split sentences in the document by both '.' and '?'\n",
    "        sentences = re.split(r'[.?]+', text)\n",
    "        \n",
    "        # Filter out empty sentences after split\n",
    "        sentences = [sentence.strip() for sentence in sentences if sentence.strip()]\n",
    "\n",
    "        # Generate embeddings for all sentences in the document\n",
    "        doc_embeddings = model.encode(sentences)\n",
    "\n",
    "        # Store the list of embeddings for the document\n",
    "        df.at[index, 'embeddings'] = [embedding.tolist() for embedding in doc_embeddings]\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save transcript text to a dataframe, clean, and apply embedding function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's first create a simple df with filenames and associated text\n",
    "\n",
    "def collect_txt_files_data(directory_path):\n",
    "    filepaths = []\n",
    "    contents = []\n",
    "    \n",
    "    for root, dirs, files in os.walk(directory_path):\n",
    "        for file in files:\n",
    "            if file.endswith('.txt'):\n",
    "                filepath = os.path.join(root, file)\n",
    "                filepaths.append(filepath)\n",
    "                \n",
    "                with open(filepath, 'r', encoding='utf-8') as f:\n",
    "                    contents.append(f.read())\n",
    "    \n",
    "    return filepaths, contents\n",
    "\n",
    "\n",
    "def save_data_to_csv(filepaths, contents, output_path):\n",
    "    df = pd.DataFrame({\n",
    "        'filepath': filepaths,\n",
    "        'transcript': contents\n",
    "    })\n",
    "    \n",
    "    df.to_csv(output_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all transcripts to one csv\n",
    "directory_path = # ADD TRANSCRIPT INPUT\n",
    "output_path_csv = # ADD DESIRED CSV OUTPUT\n",
    "\n",
    "filepaths, contents = collect_txt_files_data(directory_path)\n",
    "save_data_to_csv(filepaths, contents, output_path_csv)\n",
    "\n",
    "data = pd.read_csv(output_path_csv)\n",
    "\n",
    "labels = pd.read_csv(# ADD MANUAL SEARCH/ NO SEARCH LABELS HERE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove any timestamps from transcripts\n",
    "\n",
    "def clean_transcript(transcript):\n",
    "    \"\"\"\n",
    "    Removes timestamps and unnecessary new lines from the transcript.\n",
    "    \n",
    "    Parameters:\n",
    "    transcript (str): The transcript text.\n",
    "    \n",
    "    Returns:\n",
    "    str: Cleaned transcript without timestamps and unnecessary new lines.\n",
    "    \"\"\"\n",
    "    # Check if the input is a string\n",
    "    if not isinstance(transcript, str):\n",
    "        return transcript\n",
    "    \n",
    "    # Regular expression to match timestamps in the format 'number - number'\n",
    "    timestamp_pattern = r'\\d+\\s*-\\s*\\d+'\n",
    "\n",
    "    # Remove timestamps\n",
    "    cleaned_transcript = re.sub(timestamp_pattern, '', transcript)\n",
    "    \n",
    "    # Remove unnecessary new lines and extra spaces\n",
    "    cleaned_transcript = re.sub(r'\\s*\\n\\s*', ' ', cleaned_transcript).strip()\n",
    "    \n",
    "    return cleaned_transcript\n",
    "\n",
    "\n",
    "# Clean the transcripts\n",
    "data['transcript'] = data['transcript'].apply(clean_transcript)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# great! now lets encode our all sentences in our fancy new transcript dataframe\n",
    "data_encoded_sbert= encode_sentences_sbert(data, 'transcript')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find closest cosine distance for each transcript given a target phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_closest_sentences_sbert(df, transcript_column, embeddings_column, target_sentence, model):\n",
    "    # Format the target sentence to create a valid column name\n",
    "    target_phrase_column = \"_\".join(target_sentence.split()) + \"_cosine_distance\"\n",
    "    \n",
    "    # Use the provided model to encode the target sentence\n",
    "    target_embedding = encode_texts_sbert([target_sentence], model)[0]\n",
    "\n",
    "    # Initialize columns for the cosine distance and the closest sentence text\n",
    "    df[target_phrase_column] = np.nan\n",
    "    text_column = target_phrase_column + '_text'\n",
    "    df[text_column] = None\n",
    "\n",
    "    for index, row in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "        sentence_embeddings = row[embeddings_column]\n",
    "        sentences = re.split(r'[.?\\n]+', row[transcript_column])\n",
    "        sentences = [sentence.strip() for sentence in sentences if sentence.strip()]\n",
    "\n",
    "        if not sentences:  # Skip if there are no sentences\n",
    "            continue\n",
    "\n",
    "        # Calculate cosine similarity between the target and all sentence embeddings\n",
    "        similarities = [np.dot(target_embedding, embedding) / (np.linalg.norm(target_embedding) * np.linalg.norm(embedding)) for embedding in sentence_embeddings]\n",
    "        \n",
    "        # Find the index of the highest similarity score\n",
    "        max_similarity_index = np.argmax(similarities)\n",
    "        \n",
    "        # Update the dataframe with the closest sentence and its similarity score\n",
    "        df.at[index, target_phrase_column] = similarities[max_similarity_index]\n",
    "        df.at[index, text_column] = sentences[max_similarity_index]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean transcription and embedding columns\n",
    "data_final = data_encoded_sbert\n",
    "data_encoded_sbert['transcript'] = data_encoded_sbert['transcript'].apply(lambda x: str(x) if pd.notnull(x) else \"\")\n",
    "data_encoded_sbert['embeddings'] = data_encoded_sbert['embeddings'].apply(lambda x: np.array(ast.literal_eval(x)) if isinstance(x, str) else x)\n",
    "\n",
    "# Initialize model outside of any functions\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment with feature importance (linear model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heres the general idea for the following feature importance process: We will make a very large list containing any possible sentences whose semantic meaning may increase probability of a search occuring (ie our candidate sentences). We will then calculate cosine similarity between each candidate sentence and the closest matching sentence in every transcript. \n",
    "\n",
    "### Finally, utilizing these highest cosine similarity values we will run 50,000 logistic regressions with L1 regularization and different train/test splits for each iteration. Through this process, we will keep track of how many times each target phrase's cosine similarity score (or other extracted features) are significantly predictive and then return featues that are significantly predictive for the most train/test splits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List all potential predictive sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript_sentences = [\n",
    "    \"Can you pop the thing so I can look at that sticker just to make sure that matches the paperwork?\",\n",
    "    \"So you understand that I'm asking to search the vehicle.\",\n",
    "    \"Is it okay if I look?\",\n",
    "    \"Can I look at those bags in the back?\",\n",
    "    \"Can you open up the back for me?\",\n",
    "    \"Go to search the vehicle.\",\n",
    "    \"And he's got marijuana.\",\n",
    "    \"Did you search him?\",\n",
    "    \"Use your body cam to take pictures.\",\n",
    "    \"So let me finish searching the front\",\n",
    "    \"I just wanted to finish getting this search.\",\n",
    "    \"Ten six searched.\",\n",
    "    \"I just wanted to finish getting this search.\",\n",
    "    \"One set of plates, three fixed blade knives, one pair of bolt cutters.\",\n",
    "    \"Alright, well, I'm going to take them and return to DMV because I'm assuming they're not registered to you.\",\n",
    "    \"So what's on the property receipt?\",\n",
    "    \"So apparently the window doesn't roll up all the way?\",\n",
    "    \"I took my gloves off, man.\",\n",
    "    \"I'm not going digging back in your center console again.\",\n",
    "    \"All right, anything sharp, any needles, anything like that?\",\n",
    "    \"You widen your stance a little bit.\",\n",
    "    \"Anything in your boots?\",\n",
    "    \"Any needles?\",\n",
    "    \"Nothing tucked in your belt?\",\n",
    "    \"We found a bottle of pills in the glove box.\",\n",
    "    \"Step out for me.\",\n",
    "    \"Anything on you?\",\n",
    "    \"I'm going to search you real quick, okay?\",\n",
    "    \"Hands on the hood.\",\n",
    "    \"No needles?\",\n",
    "    \"You can smell it from here.\",\n",
    "    \"They stopped a guy because this rig just reeked of marijuana.\",\n",
    "    \"Nothing sharp or anything in your pockets?\",\n",
    "    \"You mind if we go in there and get whatever you're talking about?\",\n",
    "    \"When you get out, I'll pat you down\",\n",
    "    \"Were you drinking already, or was that already in here?\",\n",
    "    \"What's in the backseat of my car?\",\n",
    "    \"So we're going to take you back to my car, make sure you don't have anything on you you're not supposed to have, okay?\",\n",
    "    \"Is there anything in the car that we need to be worried about?\",\n",
    "    \"Any marijuana or anything?\",\n",
    "    \"Guns, drugs, bazookas, bombs?\",\n",
    "    \"What's in this pocket?\",\n",
    "    \"I'm just going to detain you real quick, alright?\",\n",
    "    \"Anything illegal in the car?\",\n",
    "    \"To search it.\",\n",
    "    \"And do you got anything that's going to poke me, make me bleed?\",\n",
    "    \"Did you just recently use some math or anything like that?\",\n",
    "    \"Did you just recently use some meth or anything like that?\",\n",
    "    \"I  might have a knife in my left pocket\",\n",
    "    \"In your left pocket?\",\n",
    "    \"So you got anything illegal on your person?\",\n",
    "    \"Something in the backpack\",\n",
    "    \"So where's the knife located?\",\n",
    "    \"Search the meth pipe, lesion, straw.\",\n",
    "    \"Can you open your driver door for me so I can take a look at the door tag?\",\n",
    "    \"Any marijuana or anything in here?\",\n",
    "    \"Get your fucking hands out the window.\",\n",
    "    \"Keep your hands up.\",\n",
    "    \"Code for one in custody.\",\n",
    "    \"You got search instrument to arrest me.\",\n",
    "    \"Go glove up.\",\n",
    "    \"If you want to get the front, I'll get the back.\",\n",
    "    \"Watch out for sharps.\",\n",
    "    \"Was that a weed pipe or a different pipe there at the floorboard?\",\n",
    "    \"This here just weed.\",\n",
    "    \"Yeah, the screwdriver and one blade.\",\n",
    "    \"Under the center console.\",\n",
    "    \"If you want to hop out, we'll do a quick patch, make sure you don't have anything you're not supposed to have, and we'll go from there.\",\n",
    "    \"If you want to hop out, we'll do a quick pat, make sure you don't have anything you're not supposed to have, and we'll go from there.\",\n",
    "    \"Anything illegal?\",\n",
    "    \"I got pot in the car, but that's it.\",\n",
    "    \"Heroin, needles?\",\n",
    "    \"Any guns in the car?\",\n",
    "    \"Put your hands on the car there\"\n",
    "]\n",
    "\n",
    "generated_sentences = [\n",
    "    \"Mind if I check the trunk for anything unusual?\",\n",
    "    \"I need to verify the VIN number against your registration.\",\n",
    "    \"Could you step to the side while we conduct the search?\",\n",
    "    \"We're looking for any illegal substances or items.\",\n",
    "    \"Please remain calm while we complete our inspection.\",\n",
    "    \"Do you have any firearms in the vehicle?\",\n",
    "    \"I noticed your taillight is out; I'll need to take a closer look.\",\n",
    "    \"We received a report of suspicious activity in this area.\",\n",
    "    \"I'm going to run your plates through the system.\",\n",
    "    \"Have you been involved in any recent criminal activity?\",\n",
    "    \"Please provide your driver's license and registration.\",\n",
    "    \"We're conducting random security checks today.\",\n",
    "    \"Do you consent to a search of your vehicle?\",\n",
    "    \"I'm detecting the odor of illegal substances.\",\n",
    "    \"We found a suspicious package under the seat.\",\n",
    "    \"You're not carrying any stolen goods, are you?\",\n",
    "    \"Have there been any alterations to your vehicle?\",\n",
    "    \"We'll need to take a closer look at your documents.\",\n",
    "    \"Is there a reason your vehicle smells like alcohol?\",\n",
    "    \"You seem nervous; is there anything you'd like to tell me?\",\n",
    "    \"Are these items yours or do they belong to someone else?\",\n",
    "    \"We're going to need to detain this item for further investigation.\",\n",
    "    \"Do you have anything in your pockets that I should know about?\",\n",
    "    \"We're checking vehicles for safety compliance.\",\n",
    "    \"Your vehicle matches the description of one reported stolen.\",\n",
    "    \"I'm going to need backup to conduct a thorough search.\",\n",
    "    \"Have you given anyone else permission to use your vehicle?\",\n",
    "    \"There's been a report of illegal activity in this make and model.\",\n",
    "    \"We need to verify the ownership of this vehicle.\",\n",
    "    \"Your vehicle was seen leaving the scene of a crime.\",\n",
    "    \"I'll need to document everything in your vehicle.\",\n",
    "    \"Is there a legal reason you have this equipment?\",\n",
    "    \"We're investigating a series of incidents in this neighborhood.\",\n",
    "    \"Your cooperation is appreciated during this process.\",\n",
    "    \"I'm going to check the vehicle's undercarriage.\",\n",
    "    \"Are you aware it's illegal to transport these items?\",\n",
    "    \"We'll need to test this substance for narcotics.\",\n",
    "    \"Do you have any proof of purchase for these items?\",\n",
    "    \"I'm going to need to see inside your glove compartment.\",\n",
    "    \"You're required by law to comply with this search.\",\n",
    "    \"Please explain why you have this amount of cash.\",\n",
    "    \"We're conducting checks for national security reasons.\",\n",
    "    \"Your vehicle has been identified in a recent investigation.\",\n",
    "    \"I'll be recording this interaction for our records.\",\n",
    "    \"Do you have any objection to me looking in the backseat?\",\n",
    "    \"We need to ensure there are no contraband or weapons.\",\n",
    "    \"Please step back while I inspect the exterior.\",\n",
    "    \"Are these substances prescribed to you?\",\n",
    "    \"I'll need to verify these serial numbers.\",\n",
    "    \"Your license plate came back with several alerts.\",\n",
    "    \"I'm required to inform you of your rights before the search.\",\n",
    "    \"We've had reports of trafficking in this area.\",\n",
    "    \"I'm checking for any modifications to your vehicle.\",\n",
    "    \"This is a routine check for DUI enforcement.\",\n",
    "    \"Your vehicle's description matches a recent alert.\",\n",
    "    \"We're looking for a missing person; have you seen anyone suspicious?\",\n",
    "    \"I'll need to take this for further examination.\",\n",
    "    \"You have the right to refuse, but that may raise suspicion.\",\n",
    "    \"I'll be checking for any hidden compartments.\",\n",
    "    \"This area is known for drug smuggling.\",\n",
    "    \"We need to clear your vehicle before you proceed.\",\n",
    "    \"I'm going to run a check on these items.\",\n",
    "    \"Please remain here while I call for a K-9 unit.\",\n",
    "    \"Your cooperation can significantly speed up this process.\",\n",
    "    \"We're conducting a safety inspection on all vehicles in this area.\"\n",
    "]\n",
    "\n",
    "generated_sentences += [\n",
    "    \"Please keep your hands where I can see them while I inspect the vehicle.\",\n",
    "    \"I'm checking for any objects that might be considered a threat.\",\n",
    "    \"This search is for our safety and yours.\",\n",
    "    \"We're almost done here, just a few more areas to check.\",\n",
    "    \"I appreciate your patience during this process.\",\n",
    "    \"Everything seems in order, but I need to check one last thing.\",\n",
    "    \"Your cooperation is making this much easier, thank you.\",\n",
    "    \"I'm looking for anything that might be hidden out of plain sight.\",\n",
    "    \"This is standard procedure, we do this for all traffic stops in this area.\",\n",
    "    \"I'll need to look under the seats, can you please step out?\",\n",
    "    \"Do you have a spare key? I need to open the trunk.\",\n",
    "    \"It's policy to check all compartments for any illegal items.\",\n",
    "    \"Have you had any issues with the vehicle's locking mechanisms?\",\n",
    "    \"I'm going to use a flashlight to look into darker areas of the car.\",\n",
    "    \"I noticed some irregularities with your vehicle's documentation.\",\n",
    "    \"Your vehicle fits the description of one involved in recent incidents.\",\n",
    "    \"We're almost finished; just need to verify a few more details.\",\n",
    "    \"For documentation purposes, I need to take a few photos.\",\n",
    "    \"Do you have any luggage or other large items in the vehicle?\",\n",
    "    \"I need to confirm the serial numbers on some of your belongings.\",\n",
    "    \"We're looking for specific items related to our current investigation.\",\n",
    "    \"Your vehicle's registration number has been flagged for a routine check.\",\n",
    "    \"I'm going to call in to confirm some details about your vehicle.\",\n",
    "    \"Please provide the insurance information for your vehicle.\",\n",
    "    \"Have you recently purchased anything of high value?\",\n",
    "    \"I'm required to check the vehicle identification number directly.\",\n",
    "    \"Your vehicle has been marked for a random safety inspection.\",\n",
    "    \"I'll need to remove some of the items to get a better look.\",\n",
    "    \"Can you explain why there's a discrepancy with your vehicle's records?\",\n",
    "    \"We're conducting a thorough investigation, and your vehicle is part of it.\",\n",
    "    \"There's been an alert for vehicles of this make and model.\",\n",
    "    \"I'll need to cross-reference the VIN with the national database.\",\n",
    "    \"Please detail the contents of any containers or packages in the car.\",\n",
    "    \"We're ensuring that there are no hazards within the vehicle.\",\n",
    "    \"I'll need to inspect any electronic devices found within the vehicle.\",\n",
    "    \"Your vehicle's color and make match a description we've been given.\",\n",
    "    \"For the next part of the inspection, I may need some additional tools.\",\n",
    "    \"We're verifying the ownership of all high-value items in the vehicle.\",\n",
    "    \"I'm checking for compliance with the latest safety regulations.\",\n",
    "    \"Your patience is appreciated while we ensure everything is in order.\",\n",
    "    \"The vehicle's condition suggests it might have been used for specific activities.\",\n",
    "    \"We're collecting evidence as part of a larger investigation.\",\n",
    "    \"I'll be looking for any modifications that might not comply with regulations.\",\n",
    "    \"This inspection helps us ensure that all vehicles are safe and legal.\",\n",
    "    \"Please confirm whether you've given anyone else access to your vehicle recently.\",\n",
    "    \"We're nearly through; just a few more checks to complete.\",\n",
    "    \"Your vehicle's type has been associated with certain risks, requiring a detailed check.\",\n",
    "    \"I'll need to consult with my supervisor on a few details about this search.\",\n",
    "    \"We're working to prevent and deter illegal activities in this area.\",\n",
    "    \"This procedure is part of our commitment to public safety.\",\n",
    "    \"I'm finalizing the report on this search; thank you for your cooperation.\",\n",
    "]\n",
    "\n",
    "irrelevant_sentences = [\n",
    "    'Fold in the cream cheese',\n",
    "    \"I'm hungry\",\n",
    "    \"Back off! Im not joking around.\",\n",
    "    \"Let's go buy a backpack\"\n",
    "]\n",
    "\n",
    "# Combining original and additional sentences into one list\n",
    "all_sentences = transcript_sentences + generated_sentences + irrelevant_sentences\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance Process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create embeddings for all candidate sentences\n",
    "for sentence in all_sentences:\n",
    "    target_sentence = sentence\n",
    "    data_final = find_closest_sentences_sbert(data_encoded_sbert, 'transcript','embeddings', target_sentence, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create one dataframe with video info AND labels\n",
    "def extract_filename(filepath):\n",
    "    \"\"\"\n",
    "    Function to extract the string after the last '/' in a sequence.\n",
    "    \"\"\"\n",
    "    return filepath.split('/')[-1]\n",
    "\n",
    "# Apply the function to the 'filepath' column of data_final\n",
    "data_final['filepath'] = data_final['filepath'].apply(extract_filename)\n",
    "\n",
    "# Apply the function to the 'File' column of labels\n",
    "labels['File'] = labels['File'].apply(extract_filename)\n",
    "\n",
    "merged_df = data_final.merge(labels, left_on='filepath', right_on='File', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean merged_df\n",
    "merged_df = merged_df.drop('Dylan Confirmation Needed', axis = 1)\n",
    "merged_df = merged_df.loc[:, ~merged_df.columns.str.startswith('Unnamed')]\n",
    "merged_df = merged_df.loc[:, ~merged_df.columns.str.endswith('_text')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract additional features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create feature for number of question marks\n",
    "def count_questions_and_sentences(row):\n",
    "    # Counting the number of question marks\n",
    "    num_questions = row['transcript'].count('?')\n",
    "    \n",
    "    # Counting the number of sentences. Assuming sentences end with '.', '!', or '?'\n",
    "    num_sentences = sum(row['transcript'].count(marker) for marker in ['.', '!', '?'])\n",
    "    \n",
    "    return pd.Series([num_questions, num_sentences], index=['num_questions', 'num_sentences'])\n",
    "\n",
    "# Apply the function along the rows (axis=1) and create new columns in the DataFrame\n",
    "merged_df[['num_questions', 'num_sentences']] = merged_df.apply(count_questions_and_sentences, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate aggregated embeddings\n",
    "\n",
    "merged_df['mean_embedding'] = ''\n",
    "merged_df['sum_embedding'] = ''\n",
    "merged_df['mean_embeddings_final_5'] = ''\n",
    "merged_df['mean_embeddings_first_5'] = ''\n",
    "for i in range(len(merged_df)):\n",
    "    merged_df['mean_embedding'][i] = np.mean(merged_df['embeddings'][i])\n",
    "    merged_df['sum_embedding'][i] = np.sum(merged_df['embeddings'][i])\n",
    "    merged_df['mean_embeddings_final_5'][i] = np.mean(merged_df['embeddings'][i][-5:])\n",
    "    merged_df['mean_embeddings_first_5'][i] = np.mean(merged_df['embeddings'][i][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add counts for keywords\n",
    "\n",
    "def count_keywords_in_transcripts_case_insensitive(dataframe, keywords):\n",
    "    # Adjusting the count_keywords function to correctly handle case-insensitive search\n",
    "    def count_keywords_case_insensitive(text, keywords):\n",
    "        text = text.lower()  # Convert text to lowercase\n",
    "        return {keyword: text.count(keyword.lower()) for keyword in keywords}\n",
    "\n",
    "    # Apply the counting function to the 'transcript' column and separate the counts into new columns\n",
    "    for keyword in keywords:\n",
    "        dataframe[keyword + '_count'] = dataframe['transcript'].apply(lambda x: count_keywords_case_insensitive(x, [keyword])[keyword])\n",
    "\n",
    "    return dataframe\n",
    "\n",
    "# Applying the corrected function\n",
    "keywords = ['confiscated', 'confiscate', 'search', 'marijuana', 'consent', 'weed', 'look', 'open', 'trunk']\n",
    "merged_df = count_keywords_in_transcripts_case_insensitive(merged_df, keywords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = merged_df.copy()\n",
    "\n",
    "data.fillna(0, inplace=True)\n",
    "\n",
    "X = data.drop(['Search?', 'transcript', 'embeddings', 'File'], axis = 1)\n",
    "\n",
    "y = data['Search?']\n",
    "\n",
    "X_train_files, X_test_files, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state =13)\n",
    "\n",
    "X_train = X_train_files.drop('filepath', axis = 1)\n",
    "X_test = X_test_files.drop('filepath', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first let's rescale our data\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler to the data and transform it\n",
    "x_train_sc_array = scaler.fit_transform(X_train)\n",
    "x_test_sc_array = scaler.transform(X_test)\n",
    "\n",
    "# Convert the scaled array back to a DataFrame\n",
    "x_train_sc = pd.DataFrame(x_train_sc_array, columns=X_train.columns)\n",
    "x_test_sc = pd.DataFrame(x_test_sc_array, columns=X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = merged_df.drop('transcript', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's write a loop that selects only features that are most frequently relevant across different train/test splits\n",
    "relevant_features = []\n",
    "for _ in range(50000):\n",
    "    # Train test split\n",
    "    data = merged_df.copy()\n",
    "    data.fillna(0, inplace=True)\n",
    "    X = data.drop(['Search?', 'filepath', 'File', 'embeddings'], axis = 1)\n",
    "    y = data['Search?']\n",
    "    X_train_loop, X_test_loop, y_train_loop, y_test_loop = train_test_split(X, y, test_size=0.25) # don't add a random state here!\n",
    "\n",
    "    # Scale\n",
    "    scaler = StandardScaler()\n",
    "    x_train_sc_array = scaler.fit_transform(X_train_loop)\n",
    "    x_train_sc_loop = pd.DataFrame(x_train_sc_array, columns=X_train_loop.columns)\n",
    "\n",
    "    # Fit the logistic regression model with L1 regularization\n",
    "    model = LogisticRegression(penalty='l1', solver='liblinear')  # 'liblinear' solver supports L1 penalty\n",
    "    model.fit(x_train_sc_loop, y_train_loop)\n",
    "\n",
    "    # Get indices of non-zero coefficients\n",
    "    non_zero_indices = [i for i, coef in enumerate(model.coef_.flatten()) if coef != 0]\n",
    "\n",
    "    # Map indices to column names\n",
    "    selected_feature_names = x_train_sc_loop.columns[non_zero_indices]\n",
    "\n",
    "    temporary_list = selected_feature_names.tolist()\n",
    "\n",
    "    relevant_features += temporary_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"You_mind_if_we_go_in_there_and_get_whatever_you're_talking_about?_cosine_distance\",\n",
       " 'This_is_standard_procedure,_we_do_this_for_all_traffic_stops_in_this_area._cosine_distance',\n",
       " 'trunk_count',\n",
       " 'Can_you_pop_the_thing_so_I_can_look_at_that_sticker_just_to_make_sure_that_matches_the_paperwork?_cosine_distance',\n",
       " 'We_found_a_bottle_of_pills_in_the_glove_box._cosine_distance',\n",
       " \"When_you_get_out,_I'll_pat_you_down_cosine_distance\",\n",
       " 'open_count',\n",
       " 'Go_glove_up._cosine_distance',\n",
       " 'Can_you_open_your_driver_door_for_me_so_I_can_take_a_look_at_the_door_tag?_cosine_distance',\n",
       " 'Did_you_search_him?_cosine_distance']"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = pd.DataFrame(relevant_features).value_counts()[:10] # pick top ten phrases\n",
    "x = x.reset_index()\n",
    "significant_features = list(x[0])\n",
    "significant_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the original X_train DataFrame to keep only significant features\n",
    "X_train_filtered = X_train[significant_features]\n",
    "\n",
    "# Filter the scaled x_train_sc DataFrame similarly\n",
    "x_train_sc_filtered = x_train_sc[significant_features]\n",
    "\n",
    "x_test_sc_filtered = x_test_sc[significant_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# After determining most predictive features, train a logistic regression classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_logistic_and_find_best_score(X_train: pd.DataFrame, \n",
    "                                     y_train,\n",
    "                                     alphas: np.array = [1e-3, 1e-3, 1e-2, 1e-1, 1, 5, 10],\n",
    "                                     n_splits: int = 10,\n",
    "                                     random_state: int = 13) -> dict:\n",
    "    best_alpha = alphas[0]\n",
    "    best_recall = 0  # Focus on recall for optimization\n",
    "    best_accuracy = 0\n",
    "    best_precision = 0\n",
    "    best_coefficients = None\n",
    "\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "\n",
    "    for alpha in alphas:\n",
    "        fold_accuracies = []\n",
    "        fold_precisions = []\n",
    "        fold_recalls = []\n",
    "        \n",
    "        for train_index, val_index in kf.split(X_train):\n",
    "            X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "            y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n",
    "\n",
    "            # Scale for each fold\n",
    "            scaler = StandardScaler()\n",
    "            X_train_fold_norm = scaler.fit_transform(X_train_fold)\n",
    "            X_val_fold_norm = scaler.transform(X_val_fold)\n",
    "            \n",
    "            # Logistic Regression with L1 penalty\n",
    "            # Define model (be sure to balance imbalanced data)\n",
    "            model = LogisticRegression(penalty='l1', C=1/alpha, solver='liblinear', random_state=random_state, class_weight='balanced', max_iter=1000)\n",
    "            model.fit(X_train_fold_norm, y_train_fold)\n",
    "            predictions = model.predict(X_val_fold_norm)\n",
    "            \n",
    "            # Calculate and store each metric\n",
    "            fold_accuracies.append(accuracy_score(y_val_fold, predictions))\n",
    "            fold_precisions.append(precision_score(y_val_fold, predictions, zero_division=0))\n",
    "            fold_recalls.append(recall_score(y_val_fold, predictions, zero_division=1))\n",
    "\n",
    "\n",
    "        # Compute mean of each metric across folds\n",
    "        mean_accuracy = np.mean(fold_accuracies)\n",
    "        mean_precision = np.mean(fold_precisions)\n",
    "        mean_recall = np.mean(fold_recalls)\n",
    "\n",
    "        # Update best scores and alpha if current mean recall is higher\n",
    "        if mean_recall > best_recall:\n",
    "            best_recall = mean_recall\n",
    "            best_accuracy = mean_accuracy\n",
    "            best_precision = mean_precision\n",
    "            best_alpha = alpha\n",
    "            best_coefficients = model.coef_[0]\n",
    "\n",
    "    # Combine feature names with coefficients\n",
    "    feature_coeff_tuples = list(zip(X_train.columns, best_coefficients))\n",
    "\n",
    "    # Return a dictionary of best scores, alpha, and coefficients\n",
    "    return {\n",
    "        'best_alpha': best_alpha,\n",
    "        'best_accuracy': best_accuracy,\n",
    "        'best_precision': best_precision,\n",
    "        'best_recall': best_recall,\n",
    "        'feature_coefficients': feature_coeff_tuples\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_alpha': 1,\n",
       " 'best_accuracy': 0.9294117647058823,\n",
       " 'best_precision': 0.55,\n",
       " 'best_recall': 0.925,\n",
       " 'feature_coefficients': [(\"You_mind_if_we_go_in_there_and_get_whatever_you're_talking_about?_cosine_distance\",\n",
       "   0.39437145893747116),\n",
       "  ('This_is_standard_procedure,_we_do_this_for_all_traffic_stops_in_this_area._cosine_distance',\n",
       "   -2.6541080301863835),\n",
       "  ('trunk_count', 0.3633987877160385),\n",
       "  ('Can_you_pop_the_thing_so_I_can_look_at_that_sticker_just_to_make_sure_that_matches_the_paperwork?_cosine_distance',\n",
       "   1.1002492037698932),\n",
       "  ('We_found_a_bottle_of_pills_in_the_glove_box._cosine_distance',\n",
       "   1.1656974866001961),\n",
       "  (\"When_you_get_out,_I'll_pat_you_down_cosine_distance\", 1.0476811063132376),\n",
       "  ('open_count', -0.39963372864018526),\n",
       "  ('Go_glove_up._cosine_distance', 1.6986242739894177),\n",
       "  ('Can_you_open_your_driver_door_for_me_so_I_can_take_a_look_at_the_door_tag?_cosine_distance',\n",
       "   0.9038448003798306),\n",
       "  ('Did_you_search_him?_cosine_distance', 0.4483260856268138)]}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.reset_index(drop = True, inplace = True)\n",
    "best_model_info_L1 = fit_logistic_and_find_best_score(x_train_sc_filtered, y_train)\n",
    "best_model_info_L1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_zero_coefficients = []\n",
    "for element in best_model_info_L1['feature_coefficients']:\n",
    "    if element[1] != 0:\n",
    "        non_zero_coefficients.append(element[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"You_mind_if_we_go_in_there_and_get_whatever_you're_talking_about?_cosine_distance\",\n",
       " 'This_is_standard_procedure,_we_do_this_for_all_traffic_stops_in_this_area._cosine_distance',\n",
       " 'trunk_count',\n",
       " 'Can_you_pop_the_thing_so_I_can_look_at_that_sticker_just_to_make_sure_that_matches_the_paperwork?_cosine_distance',\n",
       " 'We_found_a_bottle_of_pills_in_the_glove_box._cosine_distance',\n",
       " \"When_you_get_out,_I'll_pat_you_down_cosine_distance\",\n",
       " 'open_count',\n",
       " 'Go_glove_up._cosine_distance',\n",
       " 'Can_you_open_your_driver_door_for_me_so_I_can_take_a_look_at_the_door_tag?_cosine_distance',\n",
       " 'Did_you_search_him?_cosine_distance']"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_zero_coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the original X_train DataFrame to keep only significant features\n",
    "X_train_filtered = X_train[non_zero_coefficients]\n",
    "\n",
    "# Filter the scaled x_train_sc DataFrame similarly\n",
    "x_train_sc_filtered = x_train_sc[non_zero_coefficients]\n",
    "\n",
    "x_test_sc_filtered = x_test_sc[non_zero_coefficients]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best_alpha': 1,\n",
       " 'best_accuracy': 0.9294117647058823,\n",
       " 'best_precision': 0.55,\n",
       " 'best_recall': 0.925,\n",
       " 'feature_coefficients': [(\"You_mind_if_we_go_in_there_and_get_whatever_you're_talking_about?_cosine_distance\",\n",
       "   0.39437145893747116),\n",
       "  ('This_is_standard_procedure,_we_do_this_for_all_traffic_stops_in_this_area._cosine_distance',\n",
       "   -2.6541080301863835),\n",
       "  ('trunk_count', 0.3633987877160385),\n",
       "  ('Can_you_pop_the_thing_so_I_can_look_at_that_sticker_just_to_make_sure_that_matches_the_paperwork?_cosine_distance',\n",
       "   1.1002492037698932),\n",
       "  ('We_found_a_bottle_of_pills_in_the_glove_box._cosine_distance',\n",
       "   1.1656974866001961),\n",
       "  (\"When_you_get_out,_I'll_pat_you_down_cosine_distance\", 1.0476811063132376),\n",
       "  ('open_count', -0.39963372864018526),\n",
       "  ('Go_glove_up._cosine_distance', 1.6986242739894177),\n",
       "  ('Can_you_open_your_driver_door_for_me_so_I_can_take_a_look_at_the_door_tag?_cosine_distance',\n",
       "   0.9038448003798306),\n",
       "  ('Did_you_search_him?_cosine_distance', 0.4483260856268138)]}"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_info_L1 = fit_logistic_and_find_best_score(x_train_sc_filtered, y_train)\n",
    "best_model_info_L1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy with custom threshold: 0.9053254437869822\n",
      "Train Precision with custom threshold: 0.5\n",
      "Train Recall with custom threshold: 1.0\n"
     ]
    }
   ],
   "source": [
    "best_alpha = best_model_info_L1['best_alpha']\n",
    "model = LogisticRegression(penalty='l1', C=1/best_alpha, solver='liblinear', random_state=32, class_weight='balanced')\n",
    "model.fit(x_train_sc_filtered, y_train)\n",
    "\n",
    "# Get probability estimates for the test data\n",
    "probabilities = model.predict_proba(x_train_sc_filtered)\n",
    "\n",
    "# Apply the custom threshold of 0.2 to the positive class's probability estimates\n",
    "custom_threshold = 0.3\n",
    "predictions_custom_threshold = (probabilities[:, 1] > custom_threshold).astype(int)\n",
    "\n",
    "# Now you can evaluate your model using these custom predictions\n",
    "test_accuracy_custom = accuracy_score(y_train, predictions_custom_threshold)\n",
    "test_precision_custom = precision_score(y_train, predictions_custom_threshold, zero_division=0)\n",
    "test_recall_custom = recall_score(y_train, predictions_custom_threshold, zero_division=0)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(f'Train Accuracy with custom threshold: {test_accuracy_custom}')\n",
    "print(f'Train Precision with custom threshold: {test_precision_custom}')\n",
    "print(f'Train Recall with custom threshold: {test_recall_custom}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finally, run trained model on unseen test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy with custom threshold: 0.8771929824561403\n",
      "Test Precision with custom threshold: 0.45454545454545453\n",
      "Test Recall with custom threshold: 0.8333333333333334\n"
     ]
    }
   ],
   "source": [
    "# Get probability estimates for the test data\n",
    "probabilities = model.predict_proba(x_test_sc_filtered)\n",
    "\n",
    "# Apply the custom threshold of 0.4 to the positive class's probability estimates\n",
    "custom_threshold = 0.3\n",
    "predictions_custom_threshold = (probabilities[:, 1] > custom_threshold).astype(int)\n",
    "\n",
    "# Now you can evaluate your model using these custom predictions\n",
    "test_accuracy_custom = accuracy_score(y_test, predictions_custom_threshold)\n",
    "test_precision_custom = precision_score(y_test, predictions_custom_threshold, zero_division=0)\n",
    "test_recall_custom = recall_score(y_test, predictions_custom_threshold, zero_division=0)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(f'Test Accuracy with custom threshold: {test_accuracy_custom}')\n",
    "print(f'Test Precision with custom threshold: {test_precision_custom}')\n",
    "print(f'Test Recall with custom threshold: {test_recall_custom}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ACLU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
